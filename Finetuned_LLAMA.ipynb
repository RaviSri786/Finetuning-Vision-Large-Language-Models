{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "005fe4ab-dcee-467a-80a1-06403a340da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /venv/main/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in /venv/main/lib/python3.10/site-packages (4.51.3)\n",
      "Requirement already satisfied: datasets in /venv/main/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: unsloth in /venv/main/lib/python3.10/site-packages (2025.4.7)\n",
      "Requirement already satisfied: trl in /venv/main/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in /venv/main/lib/python3.10/site-packages (11.2.1)\n",
      "Requirement already satisfied: numpy in /venv/main/lib/python3.10/site-packages (2.2.5)\n",
      "Requirement already satisfied: huggingface_hub in /venv/main/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: scikit-learn in /venv/main/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /venv/main/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /venv/main/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: triton==3.3.0 in /venv/main/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /venv/main/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /venv/main/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /venv/main/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: jinja2 in /venv/main/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /venv/main/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /venv/main/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /venv/main/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /venv/main/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /venv/main/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /venv/main/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /venv/main/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /venv/main/lib/python3.10/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /venv/main/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /venv/main/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /venv/main/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /venv/main/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /venv/main/lib/python3.10/site-packages (from triton==3.3.0->torch) (59.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /venv/main/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /venv/main/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: aiohttp in /venv/main/lib/python3.10/site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: pandas in /venv/main/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /venv/main/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /venv/main/lib/python3.10/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: diffusers in /venv/main/lib/python3.10/site-packages (from unsloth) (0.33.1)\n",
      "Requirement already satisfied: torchvision in /venv/main/lib/python3.10/site-packages (from unsloth) (0.22.0)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /venv/main/lib/python3.10/site-packages (from unsloth) (0.0.30)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.4.4 in /venv/main/lib/python3.10/site-packages (from unsloth) (2025.4.4)\n",
      "Requirement already satisfied: tyro in /venv/main/lib/python3.10/site-packages (from unsloth) (0.9.19)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /venv/main/lib/python3.10/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /venv/main/lib/python3.10/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /venv/main/lib/python3.10/site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: bitsandbytes in /venv/main/lib/python3.10/site-packages (from unsloth) (0.45.5)\n",
      "Requirement already satisfied: hf_transfer in /venv/main/lib/python3.10/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /venv/main/lib/python3.10/site-packages (from unsloth) (1.6.0)\n",
      "Requirement already satisfied: rich in /venv/main/lib/python3.10/site-packages (from trl) (14.0.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (6.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: msgspec in /venv/main/lib/python3.10/site-packages (from unsloth_zoo>=2025.4.4->unsloth) (0.19.0)\n",
      "Requirement already satisfied: cut_cross_entropy in /venv/main/lib/python3.10/site-packages (from unsloth_zoo>=2025.4.4->unsloth) (25.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /venv/main/lib/python3.10/site-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /venv/main/lib/python3.10/site-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /venv/main/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /venv/main/lib/python3.10/site-packages (from tyro->unsloth) (1.7.2)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /venv/main/lib/python3.10/site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /venv/main/lib/python3.10/site-packages (from tyro->unsloth) (4.4.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /venv/main/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /venv/main/lib/python3.10/site-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers datasets unsloth trl tqdm pillow numpy huggingface_hub scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac2a6ef-91dd-4d8b-963e-4eb7bd0c44ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6776/1777865981.py:6: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastVisionModel, is_bf16_supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca32b9333914ecb8c87547312de769e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os  \n",
    "import torch  \n",
    "import pandas as pd  \n",
    "from datasets import load_dataset  \n",
    "from transformers import TextStreamer  \n",
    "from unsloth import FastVisionModel, is_bf16_supported  \n",
    "from unsloth.trainer import UnslothVisionDataCollator  \n",
    "from trl import SFTTrainer, SFTConfig  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score  \n",
    "from huggingface_hub import login  \n",
    "\n",
    "# Login for Hugging Face model push/pull  \n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16ec458-5a1f-4a1d-aa8b-462bf9548f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047ecafeee624fe59de05436ba305c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/563 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244eaedb075e4d7a89626266f53dc438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/48.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46df6d5e4054187be093319ca99d94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce2175f35f04128a555cb09b26459d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2299 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9dee1e56da46ae9fb13e3674843bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ravisri/bird-presence-classification\")  \n",
    "train_samples = dataset[\"train\"]  \n",
    "test_samples  = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05cc8815-ab0b-4907-ad3f-69fda15e81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Does this image contains a bird?, Answer 0 if you can see any bird answer 1 if you can't see any bird, no other answer is valid even if the image is pixalated or blurry\"  \n",
    "\n",
    "def label_to_int(label):  # Map text '0'/0 to int 0 (bird), else 1 (no_bird)  \n",
    "    return 1 if str(label) == \"1\" else 0\n",
    "\n",
    "def convert_to_conversation(sample):  \n",
    "    conversation = [  \n",
    "        {\"role\": \"user\", \"content\": [  \n",
    "            {\"type\": \"text\", \"text\": instruction},  \n",
    "            {\"type\": \"image\", \"image\": sample[\"image\"]}  \n",
    "        ]},  \n",
    "        {\"role\": \"assistant\", \"content\": [  \n",
    "            {\"type\": \"text\", \"text\": sample[\"caption\"]}  \n",
    "        ]},  \n",
    "    ]  \n",
    "    return {  \n",
    "        \"messages\": conversation,  \n",
    "        \"label\": label_to_int(sample[\"label\"]),  \n",
    "        \"image-id\": sample[\"image-id\"],  \n",
    "        \"image\": sample[\"image\"],  \n",
    "        \"caption\": sample[\"caption\"]  \n",
    "    }  \n",
    "\n",
    "train_data = [convert_to_conversation(s) for s in train_samples]  \n",
    "test_data  = [convert_to_conversation(s) for s in test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80a1176e-5730-4b4d-8f93-37afd3f4408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 288, 1: 287})\n",
      "Counter({0: 288, 1: 287})\n"
     ]
    }
   ],
   "source": [
    "import collections  \n",
    "print(collections.Counter([s[\"label\"] for s in test_data]))  \n",
    "# Or, if you want to see the original label strings:  \n",
    "print(collections.Counter([s[\"label\"] for s in test_samples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2af8881-2b5c-4c1f-abb5-53ed3e224ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Mllama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8e742bf6414ef2a72046fe325f40a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.vision_model.transformer` require gradients\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(  \n",
    "    \"unsloth/Llama-3.2-11B-Vision-Instruct\",  \n",
    "    load_in_4bit=True,  \n",
    "    use_gradient_checkpointing=\"unsloth\",  \n",
    ")  \n",
    "model = FastVisionModel.get_peft_model(  \n",
    "    model,  \n",
    "    finetune_vision_layers=True,  \n",
    "    finetune_language_layers=True,  \n",
    "    finetune_attention_modules=True,  \n",
    "    finetune_mlp_modules=True,  \n",
    "    r=16, lora_alpha=16, lora_dropout=0,  \n",
    "    bias=\"none\", random_state=3407,  \n",
    "    use_rslora=False, loftq_config=None,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7e8a714-4d7d-4596-91b0-77ed7746ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  \n",
    "\n",
    "def parse_prediction(output_text):\n",
    "    s = output_text.lower().strip()  \n",
    "    if \"no bird\" in s:  \n",
    "        pred_label = 1  # no_bird  \n",
    "    elif \"bird\" in s:  \n",
    "        pred_label = 0  # bird  \n",
    "    else:  \n",
    "        pred_label = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e81710a5-a6dd-4106-b88f-b680917c807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import torch  \n",
    "import re  \n",
    "from tqdm import tqdm  \n",
    "\n",
    "def calculate_per_class_metrics(y_true, y_pred):  \n",
    "    # For \"bird\" class (label 0)  \n",
    "    tp_bird = ((y_true == 0) & (y_pred == 0)).sum()  \n",
    "    fp_bird = ((y_true != 0) & (y_pred == 0)).sum()  \n",
    "    fn_bird = ((y_true == 0) & (y_pred != 0)).sum()  \n",
    "\n",
    "    precision_bird = tp_bird / (tp_bird + fp_bird) if (tp_bird + fp_bird) > 0 else 0  \n",
    "    recall_bird = tp_bird / (tp_bird + fn_bird) if (tp_bird + fn_bird) > 0 else 0  \n",
    "    f1_bird = 2 * precision_bird * recall_bird / (precision_bird + recall_bird) if (precision_bird + recall_bird) > 0 else 0  \n",
    "\n",
    "    # For \"no_bird\" class (label 1)  \n",
    "    tp_no_bird = ((y_true == 1) & (y_pred == 1)).sum()  \n",
    "    fp_no_bird = ((y_true != 1) & (y_pred == 1)).sum()  \n",
    "    fn_no_bird = ((y_true == 1) & (y_pred != 1)).sum()  \n",
    "\n",
    "    precision_no_bird = tp_no_bird / (tp_no_bird + fp_no_bird) if (tp_no_bird + fp_no_bird) > 0 else 0  \n",
    "    recall_no_bird = tp_no_bird / (tp_no_bird + fn_no_bird) if (tp_no_bird + fn_no_bird) > 0 else 0  \n",
    "    f1_no_bird = 2 * precision_no_bird * recall_no_bird / (precision_no_bird + recall_no_bird) if (precision_no_bird + recall_no_bird) > 0 else 0  \n",
    "\n",
    "    # Overall accuracy  \n",
    "    accuracy = (y_true == y_pred).mean()  \n",
    "\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.4f}\")  \n",
    "\n",
    "    print(\"\\nClass: Bird (label 0)\")  \n",
    "    print(f\"  Precision: {precision_bird:.4f}\")  \n",
    "    print(f\"  Recall:    {recall_bird:.4f}\")  \n",
    "    print(f\"  F1-score:  {f1_bird:.4f}\")  \n",
    "    print(f\"  TP: {tp_bird}, FP: {fp_bird}, FN: {fn_bird}\")  \n",
    "\n",
    "    print(\"\\nClass: No bird (label 1)\")  \n",
    "    print(f\"  Precision: {precision_no_bird:.4f}\")  \n",
    "    print(f\"  Recall:    {recall_no_bird:.4f}\")  \n",
    "    print(f\"  F1-score:  {f1_no_bird:.4f}\")  \n",
    "    print(f\"  TP: {tp_no_bird}, FP: {fp_no_bird}, FN: {fn_no_bird}\")  \n",
    "\n",
    "def get_predictions_fast(test_data, model, tokenizer, instruction, batch_size=8, results_file=\"test_predictions.csv\"):  \n",
    "    results = []  \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  \n",
    "    model.eval()    \n",
    "    n = len(test_data)  \n",
    "\n",
    "    for i in tqdm(range(0, n, batch_size)):  \n",
    "        batch = test_data[i:i+batch_size]  \n",
    "        messages_batch = [  \n",
    "            [  \n",
    "                {\"role\": \"user\", \"content\": [  \n",
    "                    {\"type\": \"text\", \"text\": instruction},  \n",
    "                    {\"type\": \"image\", \"image\": sample[\"image\"]}  \n",
    "                ]}  \n",
    "            ] for sample in batch  \n",
    "        ]  \n",
    "        input_texts = [  \n",
    "            tokenizer.apply_chat_template(messages, add_generation_prompt=True)  \n",
    "            for messages in messages_batch  \n",
    "        ]  \n",
    "        images = [[sample[\"image\"]] for sample in batch]  \n",
    "        try:  \n",
    "            inputs = tokenizer(  \n",
    "                images, input_texts,  \n",
    "                add_special_tokens=False,  \n",
    "                return_tensors=\"pt\",  \n",
    "                padding=True  \n",
    "            )  \n",
    "        except Exception as e:  \n",
    "            print(\"Error in batch at index\", i, \":\", e)  \n",
    "            continue  \n",
    "\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}  \n",
    "\n",
    "        with torch.no_grad():  \n",
    "            output_ids = model.generate(**inputs, max_new_tokens=8)  \n",
    "\n",
    "        for j, output in enumerate(output_ids):  \n",
    "            output_text = tokenizer.decode(output, skip_special_tokens=True).strip()  \n",
    "            s = output_text.lower()  \n",
    "            if \"no bird\" in s:  \n",
    "                pred_label = 1  \n",
    "            elif \"bird\" in s:  \n",
    "                pred_label = 0  \n",
    "            elif re.match(r\"\\D*1\\b\", s):  \n",
    "                pred_label = 1  \n",
    "            elif re.match(r\"\\D*0\\b\", s):  \n",
    "                pred_label = 0  \n",
    "            else:  \n",
    "                pred_label = None  \n",
    "            idx = i + j  \n",
    "            results.append({  \n",
    "                \"index\": idx,  \n",
    "                \"true_label\": batch[j][\"label\"],  \n",
    "                \"prediction\": pred_label,  \n",
    "                \"output_text\": output_text,  \n",
    "            })  \n",
    "\n",
    "    df = pd.DataFrame(results)  \n",
    "    df.to_csv(results_file, index=False)  \n",
    "    print(f\"Results saved to {results_file}.\")  \n",
    "    # Filter invalid predictions  \n",
    "    valid = df['prediction'].notna() & df['true_label'].notna()  \n",
    "    y_true = df.loc[valid, \"true_label\"].astype(int)  \n",
    "    y_pred = df.loc[valid, \"prediction\"].astype(int)  \n",
    "    calculate_per_class_metrics(y_true, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "287d09ad-6989-4679-9391-5a7139030f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 2,299 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 67,174,400/11,000,000,000 (0.61% trained)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 10:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.195500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.561900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.074800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.611200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastVisionModel, UnslothTrainer, UnslothTrainingArguments, UnslothVisionDataCollator  \n",
    "\n",
    "FastVisionModel.for_training(model)  \n",
    "\n",
    "training_args = UnslothTrainingArguments(  \n",
    "    per_device_train_batch_size=2,  \n",
    "    gradient_accumulation_steps=4,  \n",
    "    warmup_steps=5,  \n",
    "    max_steps=30,  \n",
    "    learning_rate=2e-4,  \n",
    "    fp16=not is_bf16_supported(),  \n",
    "    bf16=is_bf16_supported(),  \n",
    "    logging_steps=1,  \n",
    "    optim=\"adamw_8bit\",  \n",
    "    weight_decay=0.01,  \n",
    "    lr_scheduler_type=\"linear\",  \n",
    "    seed=3407,  \n",
    "    output_dir=\"outputs\",  \n",
    "    report_to=\"none\",  \n",
    "    remove_unused_columns=False,  \n",
    "    dataset_text_field=\"\",  \n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},  \n",
    "    dataset_num_proc=4,  \n",
    "    max_seq_length=2048,  \n",
    ")  \n",
    "\n",
    "trainer = UnslothTrainer(  \n",
    "    model=model,  \n",
    "    tokenizer=tokenizer,  \n",
    "    data_collator=UnslothVisionDataCollator(model, tokenizer),  \n",
    "    train_dataset=train_data,  \n",
    "    args=training_args,  \n",
    ")  \n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e706a5-e9e5-423c-b65a-e627cb5b73a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bfed44f7e84cb6a28841cdee070052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi  \n",
    "\n",
    "hub_model_id = \"ravisri/finetuned-llama-model\"  # Change as you like!  \n",
    "api = HfApi()  \n",
    "\n",
    "# Option 1: Create a repo (does nothing if it exists)  \n",
    "api.create_repo(repo_id=hub_model_id, exist_ok=True)  \n",
    "\n",
    "# Option 2: Upload with `push_to_hub`  \n",
    "model.save_pretrained(hub_model_id, push_to_hub=True)  \n",
    "tokenizer.save_pretrained(hub_model_id, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed90c67f-30c3-48c9-a6ab-51ef793645b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df1a8d9a-85aa-45e2-bf77-7b0f476acaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"finetuned-llama-model\")  \n",
    "tokenizer.save_pretrained(\"finetuned-llama-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c78c399a-be9d-4a04-abf6-3d5f97643cf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2352b1ead1a24ab7b2f2ea0c54786e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/ravisri/finetuned-llama-model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f96d58d7baa47c2af0dd4c5fdaf54ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f277bf1df540c98aa2c5a2818a5fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.push_to_hub(\"ravisri/finetuned-llama-model\")  \n",
    "tokenizer.push_to_hub(\"ravisri/finetuned-llama-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d12360-dd39-4791-bda9-3a5d3d0e67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Mllama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4410725292490ab94e268abfb7eb43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.vision_model.transformer` require gradients\n",
      "\n",
      "==== BEFORE finetuning ====\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [03:03<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to test_predictions_base.csv.\n",
      "\n",
      "Overall Accuracy: 0.5009\n",
      "\n",
      "Class: Bird (label 0)\n",
      "  Precision: 0.5009\n",
      "  Recall:    1.0000\n",
      "  F1-score:  0.6674\n",
      "  TP: 288, FP: 287, FN: 0\n",
      "\n",
      "Class: No bird (label 1)\n",
      "  Precision: 0.0000\n",
      "  Recall:    0.0000\n",
      "  F1-score:  0.0000\n",
      "  TP: 0, FP: 0, FN: 287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel  \n",
    "\n",
    "BASE_MODEL_PATH = \"unsloth/Llama-3.2-11B-Vision-Instruct\"  \n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(  \n",
    "    BASE_MODEL_PATH,  \n",
    "    load_in_4bit=True,  \n",
    "    use_gradient_checkpointing=\"unsloth\",  \n",
    ")  \n",
    "model = FastVisionModel.get_peft_model(  \n",
    "    model,  \n",
    "    finetune_vision_layers=True,  \n",
    "    finetune_language_layers=True,  \n",
    "    finetune_attention_modules=True,  \n",
    "    finetune_mlp_modules=True,  \n",
    "    r=16, lora_alpha=16, lora_dropout=0,  \n",
    "    bias=\"none\", random_state=3407,  \n",
    "    use_rslora=False, loftq_config=None,  \n",
    ")  \n",
    "\n",
    "# Evaluate BEFORE finetuning  \n",
    "print(\"\\n==== BEFORE finetuning ====\\n\")  \n",
    "# For base model:  \n",
    "get_predictions_fast(test_data, model, tokenizer, instruction, batch_size=8, results_file=\"test_predictions_base.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b8ae0531-aecc-4008-9015-da2f01564942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Mllama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-80GB. Num GPUs = 1. Max memory: 79.254 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7887f048c66f4a05a82a40512f9d6cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== AFTER finetuning ====\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [03:45<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to test_predictions_finetuned.csv.\n",
      "\n",
      "Overall Accuracy: 0.8574\n",
      "\n",
      "Class: Bird (label 0)\n",
      "  Precision: 0.8787\n",
      "  Recall:    0.8299\n",
      "  F1-score:  0.8536\n",
      "  TP: 239, FP: 33, FN: 49\n",
      "\n",
      "Class: No bird (label 1)\n",
      "  Precision: 0.8383\n",
      "  Recall:    0.8850\n",
      "  F1-score:  0.8610\n",
      "  TP: 254, FP: 49, FN: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel  \n",
    "\n",
    "BASE_MODEL_PATH = \"unsloth/Llama-3.2-11B-Vision-Instruct\"  \n",
    "ADAPTER_PATH = \"ravisri/finetuned-llama-model\" # or \"./lora_model\" if local  \n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(  \n",
    "    BASE_MODEL_PATH,  \n",
    "    load_in_4bit=True,  \n",
    "    use_gradient_checkpointing=\"unsloth\",  \n",
    ")  \n",
    "model.load_adapter(ADAPTER_PATH)  \n",
    "\n",
    "# Evaluate AFTER finetuning  \n",
    "print(\"\\n==== AFTER finetuning ====\\n\")  \n",
    "\n",
    "# For finetuned model:  \n",
    "get_predictions_fast(test_data, model, tokenizer, instruction, batch_size=8, results_file=\"test_predictions_finetuned.csv\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
