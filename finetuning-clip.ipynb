{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install open_clip_torch datasets torch torchvision scikit-learn tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:42:16.810357Z","iopub.execute_input":"2025-05-12T20:42:16.810546Z","iopub.status.idle":"2025-05-12T20:42:20.210311Z","shell.execute_reply.started":"2025-05-12T20:42:16.810527Z","shell.execute_reply":"2025-05-12T20:42:20.209572Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.11/dist-packages (2.32.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2024.11.6)\nRequirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (6.3.1)\nRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.30.2)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.2)\nRequirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.14)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import load_dataset  \n\ndataset = load_dataset(\"ravisri/bird-presence-classification\")  \ntrain_ds = dataset[\"train\"]  \ntest_ds = dataset[\"test\"]  \n\n# Your class mapping (from the Dataset Viewer)  \nclass_names = [\"bird\", \"no_bird\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:42:26.033677Z","iopub.execute_input":"2025-05-12T20:42:26.033939Z","iopub.status.idle":"2025-05-12T20:42:30.850171Z","shell.execute_reply.started":"2025-05-12T20:42:26.033912Z","shell.execute_reply":"2025-05-12T20:42:30.849586Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/563 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c510513aaef1452ca0a6040c3a3333f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/48.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dccc6d1510774a608f2ded5a233df2a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/12.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac5c4a9cbcea464eb18b21f3dbf317d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/2299 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af292754c5b14e1eb71c7aa96de27ba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/575 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84f2001ce6fd4c319f0314ddcbc96ce6"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from torchvision import transforms  \nfrom torch.utils.data import Dataset, DataLoader  \n\npreprocess = transforms.Compose([  \n    transforms.CenterCrop(224),  # Models trained on 224x224, but images are 256x256  \n    transforms.ToTensor(),  \n    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],  \n                         std=[0.26862954, 0.26130258, 0.27577711])  \n])  \n\nclass HFDataset(Dataset):  \n    def __init__(self, hf_ds, transform):  \n        self.ds = hf_ds  \n        self.transform = transform  \n\n    def __len__(self):  \n        return len(self.ds)  \n\n    def __getitem__(self, idx):  \n        row = self.ds[idx]  \n        img = row[\"image\"]  \n        label = row[\"label\"] # Already integer (0:bird, 1:no_bird)  \n        return self.transform(img), label  \n\ntrain_dataset = HFDataset(train_ds, preprocess)  \ntest_dataset  = HFDataset(test_ds, preprocess)  \n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)  \ntest_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:43:31.613603Z","iopub.execute_input":"2025-05-12T20:43:31.614548Z","iopub.status.idle":"2025-05-12T20:43:40.074118Z","shell.execute_reply.started":"2025-05-12T20:43:31.614516Z","shell.execute_reply":"2025-05-12T20:43:40.073335Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import open_clip  \nimport torch  \n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"  \nmodel, _, _ = open_clip.create_model_and_transforms(  \n    'ViT-B-32', pretrained='laion2b_s34b_b79k'  \n)  \ntokenizer = open_clip.get_tokenizer(\"ViT-B-32\")  \nmodel = model.to(device).eval()  \nFEATURE_DIM = model.visual.output_dim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:43:58.288562Z","iopub.execute_input":"2025-05-12T20:43:58.289360Z","iopub.status.idle":"2025-05-12T20:44:13.092463Z","shell.execute_reply.started":"2025-05-12T20:43:58.289334Z","shell.execute_reply":"2025-05-12T20:44:13.091671Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"265ade8fc58547b58cb96bafe6ebbc0c"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"prompts = [  \n    \"There is a bird present in the picture.\",      # label 0, \"bird\"  \n    \"There is no bird in the picture.\"              # label 1, \"no_bird\"  \n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:44:43.388271Z","iopub.execute_input":"2025-05-12T20:44:43.388564Z","iopub.status.idle":"2025-05-12T20:44:43.392216Z","shell.execute_reply.started":"2025-05-12T20:44:43.388542Z","shell.execute_reply":"2025-05-12T20:44:43.391652Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from tqdm import tqdm  \nfrom sklearn.metrics import classification_report  \n\ndef evaluate_clip_base(model, tokenizer, loader, prompts, class_names, device='cuda'):  \n    model.eval()  \n    text_tokens = tokenizer(prompts).to(device)  \n    text_features = model.encode_text(text_tokens)  \n    text_features = text_features / text_features.norm(dim=-1, keepdim=True)  \n    y_true, y_pred = [], []  \n    with torch.no_grad():  \n        for images, labels in tqdm(loader, desc=\"Zero-shot CLIP\"):  \n            images = images.to(device)  \n            image_features = model.encode_image(images)  \n            image_features = image_features / image_features.norm(dim=-1, keepdim=True)  \n            logits = 100. * image_features @ text_features.T  \n            preds = logits.argmax(dim=1).cpu().numpy()  \n            y_pred.extend(preds)  \n            y_true.extend(labels.numpy())  \n    print(\"\\n=== ZERO-SHOT CLIP ===\")  \n    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))  \n\nevaluate_clip_base(model, tokenizer, test_loader, prompts, class_names, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T20:57:55.519843Z","iopub.execute_input":"2025-05-12T20:57:55.520502Z","iopub.status.idle":"2025-05-12T20:57:57.482220Z","shell.execute_reply.started":"2025-05-12T20:57:55.520471Z","shell.execute_reply":"2025-05-12T20:57:57.481162Z"}},"outputs":[{"name":"stderr","text":"Zero-shot CLIP: 100%|██████████| 18/18 [00:01<00:00,  9.36it/s]","output_type":"stream"},{"name":"stdout","text":"\n=== ZERO-SHOT CLIP ===\n              precision    recall  f1-score   support\n\n        bird     0.8056    0.1007    0.1790       288\n     no_bird     0.5195    0.9756    0.6780       287\n\n    accuracy                         0.5374       575\n   macro avg     0.6625    0.5382    0.4285       575\nweighted avg     0.6628    0.5374    0.4281       575\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import torch.nn as nn  \nimport torch.optim as optim  \n\nclass CLIPWithHead(nn.Module):  \n    def __init__(self, base_model, feature_dim, num_classes):  \n        super().__init__()  \n        self.base_model = base_model  \n        self.head = nn.Linear(feature_dim, num_classes)  \n    def forward(self, images):  \n        with torch.no_grad():  \n            features = self.base_model.encode_image(images)  \n            features = features / features.norm(dim=-1, keepdim=True)  \n        return self.head(features)  \n\nprobe = CLIPWithHead(model, FEATURE_DIM, num_classes=2).to(device)  \n\ndef train_linear_head(probe, train_loader, num_epochs=5, lr=1e-3, device='cuda'):  \n    optimizer = optim.Adam(probe.head.parameters(), lr=lr)  \n    criterion = nn.CrossEntropyLoss()  \n    probe.train()  \n    for epoch in range(num_epochs):  \n        running_loss = 0.  \n        for images, labels in tqdm(train_loader, desc=f'Fine-tuning (Epoch {epoch+1})'):  \n            images, labels = images.to(device), labels.to(device)  \n            optimizer.zero_grad()  \n            logits = probe(images)  \n            loss = criterion(logits, labels)  \n            loss.backward()  \n            optimizer.step()  \n            running_loss += loss.item()  \n        print(f'Epoch {epoch+1} loss: {running_loss/len(train_loader):.4f}')  \n    probe.eval()  \n\ntrain_linear_head(probe, train_loader, num_epochs=100, lr=1e-3, device=device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:04:21.424002Z","iopub.execute_input":"2025-05-12T21:04:21.424324Z","iopub.status.idle":"2025-05-12T21:16:11.931348Z","shell.execute_reply.started":"2025-05-12T21:04:21.424293Z","shell.execute_reply":"2025-05-12T21:16:11.929753Z"}},"outputs":[{"name":"stderr","text":"Fine-tuning (Epoch 1): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 loss: 0.6353\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 2): 100%|██████████| 72/72 [00:07<00:00, 10.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 loss: 0.5409\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 3): 100%|██████████| 72/72 [00:07<00:00,  9.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 loss: 0.4788\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 4): 100%|██████████| 72/72 [00:07<00:00,  9.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 loss: 0.4357\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 5): 100%|██████████| 72/72 [00:07<00:00,  9.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 loss: 0.4052\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 6): 100%|██████████| 72/72 [00:07<00:00, 10.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 loss: 0.3829\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 7): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 loss: 0.3662\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 8): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 loss: 0.3528\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 9): 100%|██████████| 72/72 [00:06<00:00, 10.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 loss: 0.3420\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 10): 100%|██████████| 72/72 [00:07<00:00, 10.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 loss: 0.3333\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 11): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 loss: 0.3256\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 12): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 loss: 0.3192\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 13): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 loss: 0.3133\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 14): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 loss: 0.3085\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 15): 100%|██████████| 72/72 [00:07<00:00, 10.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15 loss: 0.3045\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 16): 100%|██████████| 72/72 [00:07<00:00, 10.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16 loss: 0.3003\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 17): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17 loss: 0.2969\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 18): 100%|██████████| 72/72 [00:07<00:00, 10.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18 loss: 0.2937\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 19): 100%|██████████| 72/72 [00:07<00:00, 10.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19 loss: 0.2903\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 20): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20 loss: 0.2874\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 21): 100%|██████████| 72/72 [00:07<00:00, 10.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21 loss: 0.2848\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 22): 100%|██████████| 72/72 [00:07<00:00, 10.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22 loss: 0.2824\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 23): 100%|██████████| 72/72 [00:07<00:00, 10.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23 loss: 0.2799\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 24): 100%|██████████| 72/72 [00:07<00:00, 10.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24 loss: 0.2780\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 25): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25 loss: 0.2764\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 26): 100%|██████████| 72/72 [00:07<00:00, 10.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26 loss: 0.2738\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 27): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27 loss: 0.2718\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 28): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28 loss: 0.2701\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 29): 100%|██████████| 72/72 [00:07<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29 loss: 0.2685\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 30): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30 loss: 0.2665\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 31): 100%|██████████| 72/72 [00:07<00:00, 10.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31 loss: 0.2653\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 32): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32 loss: 0.2638\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 33): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33 loss: 0.2619\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 34): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34 loss: 0.2610\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 35): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35 loss: 0.2595\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 36): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36 loss: 0.2576\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 37): 100%|██████████| 72/72 [00:07<00:00, 10.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37 loss: 0.2574\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 38): 100%|██████████| 72/72 [00:07<00:00, 10.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38 loss: 0.2557\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 39): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39 loss: 0.2542\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 40): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40 loss: 0.2531\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 41): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41 loss: 0.2521\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 42): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42 loss: 0.2511\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 43): 100%|██████████| 72/72 [00:07<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43 loss: 0.2501\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 44): 100%|██████████| 72/72 [00:07<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44 loss: 0.2496\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 45): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45 loss: 0.2478\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 46): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46 loss: 0.2472\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 47): 100%|██████████| 72/72 [00:07<00:00, 10.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47 loss: 0.2461\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 48): 100%|██████████| 72/72 [00:07<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48 loss: 0.2451\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 49): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49 loss: 0.2440\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 50): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 50 loss: 0.2436\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 51): 100%|██████████| 72/72 [00:07<00:00, 10.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 51 loss: 0.2433\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 52): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 52 loss: 0.2416\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 53): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 53 loss: 0.2409\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 54): 100%|██████████| 72/72 [00:07<00:00, 10.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 54 loss: 0.2400\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 55): 100%|██████████| 72/72 [00:07<00:00, 10.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 55 loss: 0.2395\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 56): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 56 loss: 0.2388\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 57): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 57 loss: 0.2378\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 58): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 58 loss: 0.2376\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 59): 100%|██████████| 72/72 [00:07<00:00, 10.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 59 loss: 0.2370\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 60): 100%|██████████| 72/72 [00:07<00:00, 10.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 60 loss: 0.2357\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 61): 100%|██████████| 72/72 [00:07<00:00, 10.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 61 loss: 0.2349\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 62): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 62 loss: 0.2344\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 63): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 63 loss: 0.2340\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 64): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 64 loss: 0.2332\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 65): 100%|██████████| 72/72 [00:07<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 65 loss: 0.2324\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 66): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 66 loss: 0.2318\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 67): 100%|██████████| 72/72 [00:07<00:00, 10.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 67 loss: 0.2309\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 68): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 68 loss: 0.2308\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 69): 100%|██████████| 72/72 [00:07<00:00, 10.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 69 loss: 0.2301\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 70): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 70 loss: 0.2294\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 71): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 71 loss: 0.2291\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 72): 100%|██████████| 72/72 [00:07<00:00, 10.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 72 loss: 0.2286\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 73): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 73 loss: 0.2279\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 74): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 74 loss: 0.2275\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 75): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 75 loss: 0.2267\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 76): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 76 loss: 0.2267\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 77): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 77 loss: 0.2258\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 78): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 78 loss: 0.2253\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 79): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 79 loss: 0.2248\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 80): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 80 loss: 0.2242\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 81): 100%|██████████| 72/72 [00:07<00:00, 10.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 81 loss: 0.2242\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 82): 100%|██████████| 72/72 [00:07<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 82 loss: 0.2233\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 83): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 83 loss: 0.2232\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 84): 100%|██████████| 72/72 [00:07<00:00, 10.19it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 84 loss: 0.2228\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 85): 100%|██████████| 72/72 [00:07<00:00, 10.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 85 loss: 0.2221\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 86): 100%|██████████| 72/72 [00:07<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 86 loss: 0.2220\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 87): 100%|██████████| 72/72 [00:07<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 87 loss: 0.2213\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 88): 100%|██████████| 72/72 [00:07<00:00, 10.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 88 loss: 0.2206\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 89): 100%|██████████| 72/72 [00:07<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 89 loss: 0.2205\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 90): 100%|██████████| 72/72 [00:07<00:00, 10.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 90 loss: 0.2198\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 91): 100%|██████████| 72/72 [00:07<00:00, 10.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 91 loss: 0.2199\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 92): 100%|██████████| 72/72 [00:07<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 92 loss: 0.2192\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 93): 100%|██████████| 72/72 [00:07<00:00, 10.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 93 loss: 0.2195\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 94): 100%|██████████| 72/72 [00:07<00:00, 10.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 94 loss: 0.2187\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 95): 100%|██████████| 72/72 [00:07<00:00, 10.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 95 loss: 0.2178\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 96): 100%|██████████| 72/72 [00:07<00:00, 10.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 96 loss: 0.2178\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 97): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 97 loss: 0.2174\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 98): 100%|██████████| 72/72 [00:07<00:00, 10.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 98 loss: 0.2168\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 99): 100%|██████████| 72/72 [00:07<00:00, 10.16it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 99 loss: 0.2163\n","output_type":"stream"},{"name":"stderr","text":"Fine-tuning (Epoch 100): 100%|██████████| 72/72 [00:07<00:00, 10.09it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 100 loss: 0.2163\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"torch.save(probe.state_dict(), \"clip_bird_probe.pt\")  \n# To reload:  \nprobe.load_state_dict(torch.load(\"clip_bird_probe.pt\"))  \nprobe.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:17:04.727389Z","iopub.execute_input":"2025-05-12T21:17:04.728040Z","iopub.status.idle":"2025-05-12T21:17:06.618355Z","shell.execute_reply.started":"2025-05-12T21:17:04.728009Z","shell.execute_reply":"2025-05-12T21:17:06.617587Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_85/3042128908.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  probe.load_state_dict(torch.load(\"clip_bird_probe.pt\"))\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"CLIPWithHead(\n  (base_model): CLIP(\n    (visual): VisionTransformer(\n      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n      (patch_dropout): Identity()\n      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (transformer): Transformer(\n        (resblocks): ModuleList(\n          (0-11): 12 x ResidualAttentionBlock(\n            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (attn): MultiheadAttention(\n              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n            )\n            (ls_1): Identity()\n            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (mlp): Sequential(\n              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n              (gelu): GELU(approximate='none')\n              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n            )\n            (ls_2): Identity()\n          )\n        )\n      )\n      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n    (transformer): Transformer(\n      (resblocks): ModuleList(\n        (0-11): 12 x ResidualAttentionBlock(\n          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n          )\n          (ls_1): Identity()\n          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (mlp): Sequential(\n            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n            (gelu): GELU(approximate='none')\n            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n          )\n          (ls_2): Identity()\n        )\n      )\n    )\n    (token_embedding): Embedding(49408, 512)\n    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (head): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"def evaluate_clip_finetuned(probe, loader, class_names, device='cuda'):  \n    probe.eval()  \n    y_true, y_pred = [], []  \n    with torch.no_grad():  \n        for images, labels in tqdm(loader, desc=\"Fine-tuned CLIP\"):  \n            images = images.to(device)  \n            logits = probe(images)  \n            preds = logits.argmax(dim=1).cpu().numpy()  \n            y_pred.extend(preds)  \n            y_true.extend(labels.numpy())  \n    print(\"\\n=== FINE-TUNED (Linear Head) ===\")  \n    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))  \n\nevaluate_clip_finetuned(probe, test_loader, class_names, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:17:14.927955Z","iopub.execute_input":"2025-05-12T21:17:14.928480Z","iopub.status.idle":"2025-05-12T21:17:16.889896Z","shell.execute_reply.started":"2025-05-12T21:17:14.928454Z","shell.execute_reply":"2025-05-12T21:17:16.889118Z"}},"outputs":[{"name":"stderr","text":"Fine-tuned CLIP: 100%|██████████| 18/18 [00:01<00:00,  9.28it/s]","output_type":"stream"},{"name":"stdout","text":"\n=== FINE-TUNED (Linear Head) ===\n              precision    recall  f1-score   support\n\n        bird     0.9173    0.8472    0.8809       288\n     no_bird     0.8576    0.9233    0.8893       287\n\n    accuracy                         0.8852       575\n   macro avg     0.8874    0.8853    0.8851       575\nweighted avg     0.8875    0.8852    0.8851       575\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"from huggingface_hub import HfApi, HfFolder, upload_folder, create_repo  \n\n# Log in (enter your token)  \nfrom huggingface_hub import login  \nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:17:53.947977Z","iopub.execute_input":"2025-05-12T21:17:53.948606Z","iopub.status.idle":"2025-05-12T21:17:53.969301Z","shell.execute_reply.started":"2025-05-12T21:17:53.948574Z","shell.execute_reply":"2025-05-12T21:17:53.968318Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221a7e913cc54a13916f1332ba28f8dd"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"repo_id = \"ravisri/clip-bird-detector\"  \napi = HfApi()  \napi.create_repo(repo_id=repo_id, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:19:21.502335Z","iopub.execute_input":"2025-05-12T21:19:21.502838Z","iopub.status.idle":"2025-05-12T21:19:21.954895Z","shell.execute_reply.started":"2025-05-12T21:19:21.502813Z","shell.execute_reply":"2025-05-12T21:19:21.954108Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"RepoUrl('https://huggingface.co/ravisri/clip-bird-detector', endpoint='https://huggingface.co', repo_type='model', repo_id='ravisri/clip-bird-detector')"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from huggingface_hub import HfApi  \n\napi = HfApi()  \napi.upload_file(  \n    path_or_fileobj=\"clip_bird_probe.pt\",    # Your local file  \n    path_in_repo=\"clip_bird_probe.pt\",       # The filename to use in the repo (can be the same)  \n    repo_id=repo_id,  \n    repo_type=\"model\"  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:21:57.202944Z","iopub.execute_input":"2025-05-12T21:21:57.203252Z","iopub.status.idle":"2025-05-12T21:22:12.434050Z","shell.execute_reply.started":"2025-05-12T21:21:57.203229Z","shell.execute_reply":"2025-05-12T21:22:12.433456Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"clip_bird_probe.pt:   0%|          | 0.00/605M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c6b271604dc4b9fab3a906ec4412186"}},"metadata":{}},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ravisri/clip-bird-detector/commit/e9b164b6ca2ee4de36a879b099ca3b3b6eaf2a48', commit_message='Upload clip_bird_probe.pt with huggingface_hub', commit_description='', oid='e9b164b6ca2ee4de36a879b099ca3b3b6eaf2a48', pr_url=None, repo_url=RepoUrl('https://huggingface.co/ravisri/clip-bird-detector', endpoint='https://huggingface.co', repo_type='model', repo_id='ravisri/clip-bird-detector'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}